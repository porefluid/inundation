{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import threading\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=ICe93pDZjZ5-0XRm8hkErxkKa3twqKQ7ORmpofxbpas&code_challenge_method=S256>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=ICe93pDZjZ5-0XRm8hkErxkKa3twqKQ7ORmpofxbpas&code_challenge_method=S256</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AX4XfWjztE4ocJmJkTJFGylYDMLbyd5pOCxhgDUoprO3d-3aXEhad8OWFAU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join(os.getcwd().replace('/code', ''), 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Sentinel-1 collection and watershed basin shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\")\n",
    "basins = ee.FeatureCollection(\"users/coreyscher/se-asia_subbasin_01min\")\n",
    "lulc = ee.Image('users/coreyscher/all_lcmaps_v3_2018_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'forest_evergreen': 2,\n",
    "          'forest_decisuous': 4,\n",
    "          'forest_mixed': 5,\n",
    "          'water': 25,\n",
    "          'urban': 13,\n",
    "          'barren': 16,\n",
    "          'grass': 10,\n",
    "          'savannah' : 9,\n",
    "          'ag_rice': 17,\n",
    "          'ag_plantation': 18,\n",
    "          'ag_pasture_crop': 12,\n",
    "          'ag_aquaculture': 21,\n",
    "          'wetland_wetland': 11,\n",
    "          'wetland_mangrove': 19,\n",
    "          'wetland_flooded_forest': 20,\n",
    "          'unclassified': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['forest_evergreen', 'forest_decisuous', 'forest_mixed', 'water', 'urban', 'barren', 'grass', 'savannah', 'ag_rice', 'ag_plantation', 'ag_pasture_crop', 'ag_aquaculture', 'wetland_wetland', 'wetland_mangrove', 'wetland_flooded_forest', 'unclassified'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set threshold variables \n",
    "\n",
    "threshold = -2\n",
    "vvOwThreshold = -18\n",
    "vhOwThreshold = -28\n",
    "connThreshold = 20\n",
    "\n",
    "## Make a dictionary of dates to loop over\n",
    "\n",
    "dates = [[\"2015-01-01\", \"2016-01-01\"],\n",
    "[\"2016-01-01\", \"2017-01-01\"],\n",
    "[\"2017-01-01\", \"2018-01-01\"],\n",
    "[\"2018-01-01\", \"2019-01-01\"],\n",
    "[\"2019-01-01\", \"2020-01-01\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a list of basins to iterate over\n",
    "basins_ids = basins.aggregate_array('ID').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descending track algorithm\n",
    "\n",
    "result = None\n",
    "def run_sub_basin(basin_id, studyStart, studyEnd):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    studyArea = basins.filterMetadata('ID', 'equals', basin_id).first()\n",
    "    \n",
    "    # ----Separate S1 by orbit type ---------------------\n",
    "    s1A = s1.filterBounds(studyArea.geometry())\\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW')).filterDate(studyStart, studyEnd).filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'))\n",
    "    s1D = s1.filterBounds(studyArea.geometry())\\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW')).filterDate(studyStart, studyEnd).filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\n",
    "    # --------------------------------------------------------------\n",
    "    \n",
    "    image_dates = s1D.aggregate_array('system:time_start')\n",
    "    # Functions\n",
    "    def medianFilt(image):\n",
    "        return image.focalMedian(15, 'square', 'meters').clip(studyArea).copyProperties(image)\n",
    "    ## map median filter \n",
    "    s1D = s1D.map(medianFilt)\n",
    "\n",
    "    def minMax(pol):\n",
    "        coll = s1D.select([pol])        \n",
    "        pol = ee.String(pol)\n",
    "        mn = coll.min().rename([pol.cat('_min')])\n",
    "        #max = coll.filterDate(lowStart, lowEnd).mean().rename([pol.cat('_max')])\n",
    "\n",
    "        mx = coll.max().rename([pol.cat('_max')]) #\n",
    "\n",
    "        mean = coll.mean().rename([pol.cat('_mean')])\n",
    "        std = coll.reduce(ee.Reducer.stdDev()).rename([pol.cat('_std')]) #.filterDate(lowStart, lowEnd)\n",
    "        count = coll.count().rename([pol.cat('_count')])\n",
    "        dif = mx.subtract(mn).rename([pol.cat('_dif')])\n",
    "        z = mx.subtract(mn).divide(std).rename([pol.cat('_z')])\n",
    "        return mx.addBands([mn, mean, std, dif, count, z]).set({'pol': pol}).toFloat()\n",
    "    \n",
    "    # Calculate relevant statistics for threshold detection \n",
    "    vh_stats = minMax('VH')\n",
    "    vv_stats = minMax('VV')\n",
    "\n",
    "    vvZMask = vv_stats.select(['VV_z']).gt(2)\n",
    "    vhZMask = vh_stats.select(['VH_z']).gt(2)\n",
    "    \n",
    "    def openWaterClass(image):\n",
    "        image = ee.Image(image)\n",
    "        filt = image.focalMedian(15, 'square', 'meters').clip(studyArea).copyProperties(image)\n",
    "        #vv = image.select(['VV']).lt(vvOwThreshold)\n",
    "        vh = ee.Image(filt).select(['VH']).lt(vhOwThreshold)\n",
    "\n",
    "\n",
    "        #vvAreaMask = vv.connectedPixelCount(1024, 'false').gt(connThreshold)\n",
    "        vhAreaMask = vh.connectedPixelCount(1024, False).gt(connThreshold)\n",
    "\n",
    "        #vv = vv.updateMask(vv.neq(0)).updateMask(vvZMask).updateMask(vvAreaMask)\n",
    "        vh = vh.updateMask(vh.neq(0)).updateMask(vhZMask).updateMask(vhAreaMask)\n",
    "\n",
    "        forest_evergreen = vh.updateMask(lulc.eq(2))\n",
    "        forest_decisuous = vh.updateMask(lulc.eq(4))\n",
    "        forest_mixed = vh.updateMask(lulc.eq(5))\n",
    "        water = vh.updateMask(lulc.eq(25))\n",
    "        urban = vh.updateMask(lulc.eq(13))\n",
    "        barren = vh.updateMask(lulc.eq(16))\n",
    "        grass = vh.updateMask(lulc.eq(10))\n",
    "        savannah = vh.updateMask(lulc.eq(9))\n",
    "        ag_rice = vh.updateMask(lulc.eq(17))\n",
    "        ag_plantation = vh.updateMask(lulc.eq(18))\n",
    "        ag_pasture_crop = vh.updateMask(lulc.eq(12))\n",
    "        ag_aquaculture = vh.updateMask(lulc.eq(21))\n",
    "        wetland_wetland = vh.updateMask(lulc.eq(11))\n",
    "        wetland_mangrove = vh.updateMask(lulc.eq(19))\n",
    "        wetland_flooded_forest = vh.updateMask(lulc.eq(20))\n",
    "        unclassified = vh.updateMask(lulc.eq(0))\n",
    "        \n",
    "        \n",
    "        com = ee.Image(forest_evergreen.copyProperties(image)).set('system:time_start', image.get('system:time_start')) \\\n",
    "                .addBands(forest_decisuous).addBands(forest_mixed).addBands(water).addBands(urban) \\\n",
    "                .addBands(barren).addBands(grass).addBands(savannah).addBands(ag_rice) \\\n",
    "                .addBands(ag_plantation).addBands(ag_pasture_crop).addBands(ag_aquaculture).addBands(wetland_wetland) \\\n",
    "                .addBands(wetland_mangrove).addBands(wetland_flooded_forest).addBands(ag_aquaculture) \\\n",
    "                .rename(['forest_evergreen', 'forest_decisuous', \\\n",
    "                        'forest_mixed', 'water', 'urban', 'barren', \\\n",
    "                        'grass', 'savannah', 'ag_rice', 'ag_plantation', \\\n",
    "                        'ag_pasture_crop', 'ag_aquaculture', 'wetland_wetland', \\\n",
    "                        'wetland_mangrove', 'wetland_flooded_forest', 'unclassified'])\n",
    "\n",
    "        reduced =com.reduceRegion(ee.Reducer.sum(),\n",
    "                  geometry=studyArea.geometry(),\n",
    "                  scale=30)\n",
    "        date = image.get('system:time_start')\n",
    "        return reduced\n",
    "    \n",
    "    descending = s1D.toList(s1D.size()).map(openWaterClass)\n",
    "    \n",
    "    return descending, image_dates\n",
    "\n",
    "# ls = []\n",
    "# for d in dates[1:2]:\n",
    "#     try:\n",
    "#         studyStart = d[0]\n",
    "#         studyEnd = d[1]\n",
    "#         data = run_sub_basin(1958, studyStart, studyEnd)[0].getInfo()\n",
    "#         i_dates = run_sub_basin(1958,  studyStart, studyEnd)[1].getInfo()\n",
    "#         data = pd.DataFrame(data)\n",
    "#         data['dates'] = pd.Series(i_dates)\n",
    "#         #data.set_index('dates', inplace=True)\n",
    "#         data\n",
    "#     except\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a log file\n",
    "\n",
    "logging.basicConfig(filename=\"logfilename.log\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runBasin(basin_id):\n",
    "    startTime = time.time()\n",
    "    dest_path = os.path.join(results_dir, 'basin_id_' + str(basin_id) +'.csv')\n",
    "    # iterate over basin IDs and build a dataframe for each\n",
    "    data = run_sub_basin(basin_id, '2018-01-01', '2019-01-01')[0].getInfo()\n",
    "    i_dates = run_sub_basin(basin_id,  '2018-01-01', '2019-01-01')[1].getInfo()\n",
    "    data_17 = run_sub_basin(basin_id, '2017-01-01', '2018-01-01')[0].getInfo()\n",
    "    i_dates_17 = run_sub_basin(basin_id,  '2017-01-01', '2018-01-01')[1].getInfo()\n",
    "    data_16 = run_sub_basin(basin_id, '2016-01-01', '2017-01-01')[0].getInfo()\n",
    "    i_dates_16 = run_sub_basin(basin_id,  '2016-01-01', '2017-01-01')[1].getInfo()\n",
    "\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['dates'] = pd.Series(i_dates)\n",
    "    df2 = pd.DataFrame(data_17)\n",
    "    df2['dates'] = pd.Series(i_dates_17)\n",
    "    df3 = pd.DataFrame(data_16)\n",
    "    df3['dates'] = pd.Series(i_dates_16)\n",
    "\n",
    "    test_time_series = df3.append(df2).append(df1)\n",
    "    test_time_series['datetimes'] = pd.to_datetime(test_time_series['dates'], unit='ms')\n",
    "    test_time_series.set_index('datetimes', inplace=True)\n",
    "    test_time_series.drop(columns=['dates'], inplace=True)\n",
    "    \n",
    "    test_time_series.to_csv(dest_path)\n",
    "    \n",
    "    executionTime = (time.time() - startTime)\n",
    "\n",
    "    logging.info('basin ID '+ str(basin_id)+ ' processed in seconds: ' + str(executionTime))\n",
    "    \n",
    "    print('basin ID '+ str(basin_id)+ ' processed in seconds: ' + str(executionTime))\n",
    "    \n",
    "    return 'completed basin id: ' + str(basin_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basin ID 22 processed in seconds: 25.408195972442627\n"
     ]
    }
   ],
   "source": [
    "for i in [22, 23]:\n",
    "    runBasin(i)\n",
    "    time.sleep(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
